<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2 | Rafael Padilha</title>
    <link>https://rafaspadilha.github.io/publication_types/2/</link>
      <atom:link href="https://rafaspadilha.github.io/publication_types/2/index.xml" rel="self" type="application/rss+xml" />
    <description>2</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 07 Mar 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>2</title>
      <link>https://rafaspadilha.github.io/publication_types/2/</link>
    </image>
    
    <item>
      <title>Content-Aware Detection of Temporal Metadata Manipulation</title>
      <link>https://rafaspadilha.github.io/publication/padilha22content/</link>
      <pubDate>Mon, 07 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://rafaspadilha.github.io/publication/padilha22content/</guid>
      <description>&lt;br&gt;
&lt;hr&gt;
&lt;br&gt;
&lt;h2 id=&#34;video-summary&#34;&gt;Video Summary&lt;/h2&gt;












  


&lt;video controls &gt;
  &lt;source src=&#34;tifs_sharing_clip.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;br&gt;
&lt;hr&gt;
&lt;br&gt;
&lt;h2 id=&#34;approach-overview&#34;&gt;Approach Overview&lt;/h2&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;
Our goal is to assess if the visual content of an outdoor image is consistent with its hour and month of capture. For this, our method must extract discriminative features from the scene appearance and contrast them with the expected appearance for that specific time of capture. As variations in appearance over time are highly dependent on the location of the scene, it is essential to provide, as additional context, geographic cues of where the picture was taken.
&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;network_architecture.png&#34; alt=&#34;Network Architecture&#34; title=&#34;Network Architecture&#34;&gt;&lt;/p&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;
With this in mind, we propose a CNN architecture to estimate the probability $P(y\,|\,G, t, l, S)$ that a given ground-level image $G$, associated with location $l$ and satellite image $S$, is consistent ($y=0$) or inconsistent ($y=1$) with an alleged timestamp $t$. By providing location $l$ as input, the network will be able to consider the influence of geographic position in seasonal patterns (e.g., winter months in the Northern hemisphere with reduced sunlight hours, and the opposite in the Southern hemisphere). Moreover,  satellite image $S$ provides an additional context about the photographer&#39;s surroundings and the structure of the scene, such as whether the image was captured in an urban or rural area. We employ a basemap-style picture, which is globally available and can be easily obtained from online services (e.g., Google Maps and Bing Maps) given location $l$. This kind of imagery was designed for navigational purposes and offers an idea of the structure of the scene without reflecting time-dependent elements (e.g., illumination and weather conditions). In this sense, we &lt;b&gt;do not&lt;/b&gt; assume $S$ is linked to the timestamp $t$, avoiding the need for a satellite image at the precise time-of-capture being checked.&lt;/p&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;For explainability, the network also estimates transient attributes $a_{\textit{G}}$ and $a_{\textit{S}}$. These are 40-dimensional arrays, with each value encoding the presence of a characteristic of the scene appearance (e.g., fog, hot, beautiful, summer) to the interval $[0,1]$. The attributes $a_{\textit{G}}$ are estimated solely from the ground-level image and capture the high-level properties of the scene at the moment it was recorded. In contrast, $a_{S}$ is estimated from the satellite photo, location coordinates, and the alleged timestamp, and can be interpreted as a prediction of the expected scene appearance at the alleged moment.
&lt;/p&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;More details about each component of the architecture can be found in the main paper.&lt;/p&gt;
&lt;br&gt;
&lt;hr&gt;
&lt;br&gt;
&lt;h2 id=&#34;experimental-analyses&#34;&gt;Experimental Analyses&lt;/h2&gt;
&lt;p style=&#34;text-align: justify;&#34;&gt;We present in the main paper and supplementary material several experiments highlighting different aspects of our method:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ablation study of each input modality and backbone architecture;&lt;/li&gt;
&lt;li&gt;Sensitivity analyses regarding changes in the appearance of the scene, subtler timestamp manipulation, and noises in the geographical coordinates;&lt;/li&gt;
&lt;li&gt;Interpretability visualizations to understand what elements influence the decision of the model;&lt;/li&gt;
&lt;li&gt;Extension of our approach to estimate a range of possible time-of-capture for a given image;&lt;/li&gt;
&lt;li&gt;Cross-camera evaluation, a realistic application scenario with social media imagery;&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;hr&gt;
&lt;br&gt;
&lt;h2 id=&#34;bibtex&#34;&gt;BibTeX&lt;/h2&gt;
&lt;pre style=&#34;overflow:auto&#34;&gt;
@article{padilha22content,
    author       = &#34;Rafael Padilha and Tawfiq Salem and Scott Workman and Fernanda A. Andaló and Anderson Rocha and Nathan Jacobs&#34;,
    title        = &#34;Content-Aware Detection of Temporal Metadata Manipulation&#34;,
    journal      = &#34;{IEEE} Transactions on Information Forensics and Security (TIFS)&#34;,
    volume       = &#34;In Press&#34;,
    year         = 2022
}
&lt;/pre&gt;&lt;blockquote&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Cross-dataset emotion recognition from facial expressions through convolutional neural networks</title>
      <link>https://rafaspadilha.github.io/publication/dias21emotion/</link>
      <pubDate>Tue, 14 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://rafaspadilha.github.io/publication/dias21emotion/</guid>
      <description>&lt;h4 id=&#34;bibtex&#34;&gt;BibTeX&lt;/h4&gt;
&lt;pre style=&#34;overflow:auto&#34;&gt;
@article{dias21cross,
    author = {William Dias and Fernanda A. Andaló and Rafael Padilha and Gabriel Bertocco and Waldir Almeida and Paula Costa and Anderson Rocha},
    title = {Cross-dataset emotion recognition from facial expressions through convolutional neural networks},
    journal = {Journal of Visual Communication and Image Representation},
    volume = {In Press},
    pages = {},
    year = {2021},
    doi = {https://doi.org/10.1016/j.jvcir.2021.103395},
}
&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Temporally Sorting Images from Real-World Events</title>
      <link>https://rafaspadilha.github.io/publication/padilha21prl/</link>
      <pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://rafaspadilha.github.io/publication/padilha21prl/</guid>
      <description>&lt;h4 id=&#34;bibtex&#34;&gt;BibTeX&lt;/h4&gt;
&lt;pre style=&#34;overflow:auto&#34;&gt;
@article{padilha21temporally,
    author = {Rafael Padilha and Fernanda A. Andaló and Bahram Lavi and Luís A.M. Pereira and Anderson Rocha},
    title = {Temporally sorting images from real-world events},
    journal = {Pattern Recognition Letters},
    volume = {147},
    pages = {212-219},
    year = {2021},
    doi = {https://doi.org/10.1016/j.patrec.2021.04.027},
}
&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>A Inteligência Artificial e os desafios da Ciência Forense Digital no século XXI</title>
      <link>https://rafaspadilha.github.io/publication/padilha21usp/</link>
      <pubDate>Mon, 19 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://rafaspadilha.github.io/publication/padilha21usp/</guid>
      <description>&lt;h3 id=&#34;bibtex&#34;&gt;Contribution Statement&lt;/h4&gt;
&lt;b&gt;Rafael Padilha&lt;/b&gt; and &lt;b&gt;Antônio Theóphilo&lt;/b&gt; have contributed equally for this work.
&lt;h4 id=&#34;bibtex&#34;&gt;BibTeX&lt;/h4&gt;
&lt;pre style=&#34;overflow:auto&#34;&gt;
@article{padilha21cfd,
    author       = &#34;Rafael Padilha and Antônio Theóphilo and Fernanda A. Andaló and Didier A. Vega-Oliveros and João P. Cardenuto and Gabriel Bertocco and José Nascimento and Jing Yang and Anderson Rocha&#34;,
    title        = &#34;A Inteligência Artificial e os desafios da Ciência Forense Digital no século XXI&#34;,
    journal      = &#34;USP Estudos Avançados&#34;,
    year         = 2021,
}
&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Detecting face presentation attacks in mobile devices with a patch-based CNN and a sensor-aware loss function</title>
      <link>https://rafaspadilha.github.io/publication/almeida20spoofing/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://rafaspadilha.github.io/publication/almeida20spoofing/</guid>
      <description>&lt;h4 id=&#34;bibtex&#34;&gt;BibTeX&lt;/h4&gt;
&lt;pre style=&#34;overflow:auto&#34;&gt;
@article{almeida20plosone,
    author       = &#34;Waldir R. Almeida and Fernanda A. Andal{\&#39;o} and Rafael Padilha and Gabriel Bertocco and William Dias and Ricardo da S. Torres and Jacques Wainer and Anderson Rocha&#34;,
    title        = &#34;Detecting face presentation attacks in mobile devices with a patch-based CNN and a sensor-aware loss function&#34;,
    journal      = &#34;PLoS ONE&#34;,
    year         = 2020,
}
&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Forensic Event Analysis: From Seemingly Unrelated Data to Understanding</title>
      <link>https://rafaspadilha.github.io/publication/padilha20forensic/</link>
      <pubDate>Tue, 07 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://rafaspadilha.github.io/publication/padilha20forensic/</guid>
      <description>&lt;h4 id=&#34;bibtex&#34;&gt;BibTeX&lt;/h4&gt;
&lt;pre style=&#34;overflow:auto&#34;&gt;
@article{padilha2020forensic,
  title={Forensic Event Analysis: From Seemingly Unrelated Data to Understanding},
  author={Padilha, Rafael and M. Rodrigues, Caroline and A. Andal{\&#39;o}, Fernanda and Bertocco, Gabriel and Dias, Zanoni and Rocha, Anderson},
  journal={IEEE Security and Privacy},
  year={2020},
  publisher={IEEE}
}
&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Two-tiered face verification with low-memory footprint for mobile devices</title>
      <link>https://rafaspadilha.github.io/publication/padilha20biometrics/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://rafaspadilha.github.io/publication/padilha20biometrics/</guid>
      <description>&lt;h4 id=&#34;bibtex&#34;&gt;BibTeX&lt;/h4&gt;
&lt;pre style=&#34;overflow:auto&#34;&gt;
@article{padilha2020two,
  title={Two-tiered face verification with low-memory footprint for mobile devices},
  author={Padilha, Rafael and Andal{\&#39;o}, Fernanda and Bertocco, Gabriel and Almeida, Waldir and Dias, William and Resek, Thiago and Torres, Ricardo and Wainer, Jacques and Rocha, Anderson},
  journal={IET Biometrics},
  volume={9},
  issue={5},
  pages={205–215},
  year={2020},
  publisher={IET}
}
&lt;/pre&gt;</description>
    </item>
    
  </channel>
</rss>
